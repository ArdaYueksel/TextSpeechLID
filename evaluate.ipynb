{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\ay07\\AppData\\Local\\Temp\\ipykernel_28092\\1993388408.py:5: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was too old on your system - pyarrow 10.0.1 is the current minimum supported version as of this release.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import fasttext\n",
    "from huggingface_hub import hf_hub_download\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHE_DIR = Path(\"IDP/cache\")\n",
    "TEXT_MODEL = \"facebook/fasttext-language-identification\"\n",
    "SPEECH_MODEL = \"facebook/mms-lid-126\"\n",
    "ASR_MODEL = \"facebook/mms-1b-fl102\"\n",
    "# TTS_MODEL ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Model\n",
    "Selected Model: Fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path_text = hf_hub_download(repo_id=TEXT_MODEL, filename=\"model.bin\")\n",
    "model_text = fasttext.load_model(model_path_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech Model Loading\n",
    "\n",
    "Selected Model: facebook/mms-lid-126\n",
    "\n",
    "Selected ASR Model: facebook/mms-1b-fl102\n",
    "\n",
    "Selected TTS Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\transformers\\utils\\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "c:\\Python310\\lib\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "c:\\Python310\\lib\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "Some weights of the model checkpoint at facebook/mms-lid-126 were not used when initializing Wav2Vec2ForSequenceClassification: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/mms-lid-126 and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import Wav2Vec2ForSequenceClassification, AutoFeatureExtractor\n",
    "import torch\n",
    "processor_speech = AutoFeatureExtractor.from_pretrained(SPEECH_MODEL, cache_dir=CACHE_DIR)\n",
    "model_speech = Wav2Vec2ForSequenceClassification.from_pretrained(SPEECH_MODEL, cache_dir=CACHE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from transformers import Wav2Vec2ForCTC, AutoProcessor\n",
    "\n",
    "processor_asr = AutoProcessor.from_pretrained(ASR_MODEL, cache_dir=CACHE_DIR)\n",
    "model_asr = Wav2Vec2ForCTC.from_pretrained(ASR_MODEL, cache_dir=CACHE_DIR)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Python310\\lib\\site-packages\\transformers\\utils\\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "c:\\Python310\\lib\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "c:\\Python310\\lib\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Can't load tokenizer for 'facebook/mms-tts'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'facebook/mms-tts' is the correct path to a directory containing all relevant files for a VitsTokenizer tokenizer.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VitsTokenizer, VitsModel, set_seed\n\u001b[1;32m----> 2\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mVitsTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfacebook/mms-tts\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m VitsModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacebook/mms-tts\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(text\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHello - my dog is cute\u001b[39m\u001b[38;5;124m\"\u001b[39m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2012\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, *init_inputs, **kwargs)\u001b[0m\n\u001b[0;32m   2006\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[0;32m   2007\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt load following files from cache: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00munresolved_files\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and cannot check if these \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2008\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfiles are necessary for the tokenizer to operate.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2009\u001b[0m     )\n\u001b[0;32m   2011\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(full_file_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m full_file_name \u001b[38;5;129;01min\u001b[39;00m resolved_vocab_files\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m-> 2012\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[0;32m   2013\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt load tokenizer for \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. If you were trying to load it from \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2014\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, make sure you don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt have a local directory with the same name. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2015\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOtherwise, make sure \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is the correct path to a directory \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2016\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontaining all relevant files for a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tokenizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2017\u001b[0m     )\n\u001b[0;32m   2019\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_id, file_path \u001b[38;5;129;01min\u001b[39;00m vocab_files\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   2020\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m file_id \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m resolved_vocab_files:\n",
      "\u001b[1;31mOSError\u001b[0m: Can't load tokenizer for 'facebook/mms-tts'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'facebook/mms-tts' is the correct path to a directory containing all relevant files for a VitsTokenizer tokenizer."
     ]
    }
   ],
   "source": [
    "from transformers import VitsTokenizer, VitsModel, set_seed\n",
    "tokenizer = VitsTokenizer.from_pretrained(\"facebook/mms-tts\",cache_dir=CACHE_DIR)\n",
    "model = VitsModel.from_pretrained(\"facebook/mms-tts\",cache_dir=CACHE_DIR)\n",
    "\n",
    "inputs = tokenizer(text=\"Hello - my dog is cute\", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Wav2Vec2ForSequenceClassification(\n",
       "  (wav2vec2): Wav2Vec2Model(\n",
       "    (feature_extractor): Wav2Vec2FeatureEncoder(\n",
       "      (conv_layers): ModuleList(\n",
       "        (0): Wav2Vec2LayerNormConvLayer(\n",
       "          (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,))\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (1-4): 4 x Wav2Vec2LayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,))\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (5-6): 2 x Wav2Vec2LayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,))\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (feature_projection): Wav2Vec2FeatureProjection(\n",
       "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (projection): Linear(in_features=512, out_features=1280, bias=True)\n",
       "      (dropout): Dropout(p=0.05, inplace=False)\n",
       "    )\n",
       "    (encoder): Wav2Vec2EncoderStableLayerNorm(\n",
       "      (pos_conv_embed): Wav2Vec2PositionalConvEmbedding(\n",
       "        (conv): ParametrizedConv1d(\n",
       "          1280, 1280, kernel_size=(128,), stride=(1,), padding=(64,), groups=16\n",
       "          (parametrizations): ModuleDict(\n",
       "            (weight): ParametrizationList(\n",
       "              (0): _WeightNorm()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (padding): Wav2Vec2SamePadLayer()\n",
       "        (activation): GELUActivation()\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.05, inplace=False)\n",
       "      (layers): ModuleList(\n",
       "        (0-47): 48 x Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.05, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (output_dropout): Dropout(p=0.05, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (adapter_layer): Wav2Vec2AttnAdapterLayer(\n",
       "            (norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (linear_1): Linear(in_features=1280, out_features=16, bias=True)\n",
       "            (act_fn): ReLU()\n",
       "            (linear_2): Linear(in_features=16, out_features=1280, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (projector): Linear(in_features=1280, out_features=1024, bias=True)\n",
       "  (classifier): Linear(in_features=1024, out_features=126, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_asr = model_asr.to(\"cuda\")\n",
    "model_speech = model_speech.to(\"cuda\")\n",
    "model_speech.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "Selected Dataset: Fleurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Worst Performing Languages According to Fasttext Model Classification Report (Below Micro Average)\n",
    "Original_Languages = ['zho_Hant',\n",
    " 'bos_Latn',\n",
    " 'hrv_Latn',\n",
    " 'kam_Latn',\n",
    " 'zho_Hans',\n",
    " 'swh_Latn',\n",
    " 'zsm_Latn',\n",
    " 'nya_Latn',\n",
    " 'ind_Latn',\n",
    " 'kea_Latn']\n",
    "\n",
    "\n",
    "\n",
    "# Dataset Codes of the Languages in the Original_Languages List\n",
    "Lang_Codes_FLEURS = ['yue_hant_hk',\n",
    "                     'bs_ba',\n",
    "                     'hr_hr',\n",
    "                     'kam_ke',\n",
    "                     'cmn_hans_cn',\n",
    "                     'sw_ke',\n",
    "                     'ms_my',\n",
    "                     'ny_mw',\n",
    "                     'id_id',\n",
    "                     'kea_cv']\n",
    "\n",
    "# ISO 693-3 Codes of Original_Languages\n",
    "Lang_Codes_XLS = ['yue',\n",
    "                  'bos',\n",
    "                  'hrv',\n",
    "                  'kam',\n",
    "                  'cmn',\n",
    "                  'swh',\n",
    "                  'zsm',\n",
    "                  'nya',\n",
    "                  'ind',\n",
    "                  'kea']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ay07\\AppData\\Roaming\\Python\\Python310\\site-packages\\datasets\\load.py:1429: FutureWarning: The repository for google/fleurs contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/google/fleurs\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "count = 0\n",
    "for lang in Lang_Codes_FLEURS:\n",
    "    fleurs = load_dataset(\"google/fleurs\", lang, split=\"test\", streaming=True)\n",
    "    for example in fleurs:\n",
    "        if(count % 100 == 0):\n",
    "            print(count)\n",
    "        count += 1\n",
    "        \n",
    "        curr_results = {}\n",
    "        curr_results['language'] = Lang_Codes_XLS[Lang_Codes_FLEURS.index(lang)]\n",
    "\n",
    "        inputs = processor_speech(example['audio']['array'], sampling_rate=16_000, return_tensors=\"pt\").to(\"cuda\")\n",
    "        with torch.no_grad():\n",
    "            outputs = model_speech(**inputs).logits.detach().cpu()\n",
    "\n",
    "        lang_id = torch.argmax(outputs, dim=-1)[0].item()\n",
    "        probabilities = torch.nn.functional.softmax(outputs, dim=-1)\n",
    "        speech_probability = probabilities[0][lang_id].item()\n",
    "\n",
    "        detected_lang_speech = model_speech.config.id2label[lang_id]\n",
    "        detected_lang_text, text_probability = model_text.predict(example['transcription'])\n",
    "        detected_lang_text = detected_lang_text[0].split('__label__')[1]\n",
    "        detected_lang_text = detected_lang_text.split('_')[0]\n",
    "        text_probability = text_probability[0]\n",
    "\n",
    "        # # ASR Model Prediction\n",
    "        # asr_inputs = processor_asr(example['audio']['array'], sampling_rate=16_000, return_tensors=\"pt\")\n",
    "        # with torch.no_grad():\n",
    "        #     outputs = model_asr(**inputs).logits.detach().cpu()\n",
    "\n",
    "        # asr_ids = torch.argmax(outputs, dim=-1)[0]\n",
    "        # asr_transcription = processor_asr.decode(asr_ids)\n",
    "        # asr_prediction, asr_probability = model_text.predict(asr_transcription)\n",
    "        # asr_prediction = asr_prediction[0].split('__label__')[1]\n",
    "        # asr_prediction = asr_prediction.split('_')[0]\n",
    "        # asr_probability = asr_probability[0]\n",
    "\n",
    "        curr_results['speech_prediction'] = detected_lang_speech\n",
    "        curr_results['speech_probability'] = speech_probability \n",
    "        curr_results['text_prediction'] = detected_lang_text\n",
    "        curr_results['text_probability'] = text_probability\n",
    "        # curr_results['asr_prediction'] = asr_prediction\n",
    "        # curr_results['asr_probability'] = asr_probability\n",
    "        results.append(curr_results)\n",
    "\n",
    "        # print(f\"Detected Language (Speech): {detected_lang_speech} with Probability: {speech_probability}\")\n",
    "        # print(f\"Detected Language (Text): {detected_lang_text} with Probability: {text_probability}\")\n",
    "        # print(f\"Detected Language (ASR): {asr_prediction} with Probability: {asr_probability}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  language speech_prediction  speech_probability text_prediction  \\\n",
      "0      yue               yue            0.999900             yue   \n",
      "1      bos               hrv            0.995476             bos   \n",
      "2      hrv               hrv            0.998369             hrv   \n",
      "3      kam               kam            0.999966             swh   \n",
      "4      cmn               cmn            0.999438             zho   \n",
      "5      swh               swh            0.998945             swh   \n",
      "6      zsm               zlm            0.999936             zsm   \n",
      "7      nya               nya            0.999918             nya   \n",
      "8      ind               ind            0.999903             ind   \n",
      "9      kea               kea            0.991431             kea   \n",
      "\n",
      "   text_probability  \n",
      "0          1.000010  \n",
      "1          0.506708  \n",
      "2          0.989321  \n",
      "3          0.938058  \n",
      "4          0.999969  \n",
      "5          0.999994  \n",
      "6          0.999691  \n",
      "7          0.971158  \n",
      "8          0.999446  \n",
      "9          0.994408  \n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(results)\n",
    "df.to_csv(\"IDP/results_speech_text.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
